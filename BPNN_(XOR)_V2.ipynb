{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BPNN (XOR) - V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyND7S7syVv8v/pSAWXFLh6h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamarulAdha/Jupyter-Notebooks/blob/main/BPNN_(XOR)_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLwduGiIfUEl"
      },
      "source": [
        "\"\"\"Import Module\"\"\"\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDkYt4ihgNM-"
      },
      "source": [
        "\"\"\"Sigmoid Activation Function\"\"\"\n",
        "def sigmoid(x):\n",
        "  return 1/(1 + np.exp(-x))\n",
        "\n",
        "\n",
        "\"\"\"Sigmoid Derivative\"\"\"\n",
        "def sigmoid_derivative(x):\n",
        "  return x * (1-x)\n",
        "\n",
        "\n",
        "\"\"\"Sum of Squared Errors\"\"\"\n",
        "def sum_squared_errors(errors):\n",
        "  sse = 0\n",
        "  for x in range(len(errors)):\n",
        "    error = float(*errors[x])\n",
        "    sse += error**2\n",
        "  return sse"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiSWE9aZj5Ru"
      },
      "source": [
        "\"\"\"Input Dataset\"\"\"\n",
        "inputs = np.array([[1,1], [0,1], [1,0], [0,0]])\n",
        "\n",
        "\"\"\"Expected Output (XOR)\"\"\"\n",
        "expected_output = np.array([[0], [1], [1], [0]])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R4V3fbVn7XU"
      },
      "source": [
        "\"\"\"Initialise Hyper-Parameters\"\"\"\n",
        "lr = 0.1\n",
        "bias = -1\n",
        "# inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvCS1GFmrLcz"
      },
      "source": [
        "\"\"\"Initialise Parameters\"\"\"\n",
        "hidden_weights = np.array([[0.5, 0.9], [0.4, 1.0]])\n",
        "hidden_thresh = np.array([[0.8, -0.1]])\n",
        "output_weights = np.array([[-1.2], [1.1]])\n",
        "output_thresh = np.array([[0.3]])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EG0LlCXqv9j"
      },
      "source": [
        "# \"\"\"Initialise Parameters\"\"\"\n",
        "# hidden_weights = np.random.uniform(size=(inputLayerNeurons, hiddenLayerNeurons))\n",
        "# hidden_thresh = np.random.uniform(size=(1, hiddenLayerNeurons))\n",
        "# output_weights = np.random.uniform(size=(hiddenLayerNeurons, outputLayerNeurons))\n",
        "# output_thresh = np.random.uniform(size=(1, outputLayerNeurons))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeD9T4ecrS1v"
      },
      "source": [
        "\"\"\"Training Algorithm\"\"\"\n",
        "epochs = 0\n",
        "errors = []\n",
        "while(True):\n",
        "  for x in range(len(inputs)):\n",
        "    \"\"\"Multiply the row of the matrix with the hidden weights\"\"\"\n",
        "    input = np.array([inputs[x,:]])\n",
        "\n",
        "    \"\"\"Feed-Forward Propagation\"\"\"\n",
        "    hidden_dot_product = np.dot(input, hidden_weights)\n",
        "    hidden_layer_activation = np.add(hidden_dot_product,(bias*hidden_thresh))\n",
        "    actual_hidden = sigmoid(hidden_layer_activation)\n",
        "\n",
        "    output_dot_product = np.dot(actual_hidden, output_weights)\n",
        "    output_layer_activation = np.add(output_dot_product, (bias*output_thresh))\n",
        "    actual_output = sigmoid(output_layer_activation)\n",
        "\n",
        "\n",
        "    \"\"\"Backpropagation\"\"\"\n",
        "    output_error = np.subtract(expected_output[x], actual_output)\n",
        "    d_output_layer = sigmoid_derivative(actual_output) * output_error\n",
        "    errors.append(*output_error.tolist())   \n",
        "\n",
        "    hidden_error = np.dot(d_output_layer, output_weights.T)\n",
        "    d_hidden_layer = sigmoid_derivative(actual_hidden) * hidden_error\n",
        "\n",
        "\n",
        "    \"\"\"Update Weights & Thresholds\"\"\"\n",
        "    output_weights += lr * np.dot(actual_hidden.T, d_output_layer)\n",
        "    output_thresh += lr * np.dot(bias, d_output_layer)\n",
        "\n",
        "    hidden_weights += lr * np.dot(input.T, d_hidden_layer)\n",
        "    hidden_thresh += lr * np.dot(bias, d_hidden_layer)\n",
        "\n",
        "  \n",
        "  \"\"\"Sum of Squared Errors\"\"\"\n",
        "  sse = sum_squared_errors(errors)\n",
        "\n",
        "  \"\"\"Increment Epoch\"\"\"\n",
        "  epochs += 1\n",
        "\n",
        "  \"\"\"Exit Condition\"\"\"\n",
        "  if (sse<=0.001 or epochs>100000):\n",
        "    break\n",
        "  else:\n",
        "    errors.clear()   "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzh6K5E546V5"
      },
      "source": [
        "\"\"\"Testing\"\"\"\n",
        "hidden_dot_product = np.dot(inputs, hidden_weights)\n",
        "hidden_layer_activation = np.add(hidden_dot_product, (bias*hidden_thresh))\n",
        "actual_hidden = sigmoid(hidden_layer_activation)\n",
        "\n",
        "output_dot_product = np.dot(actual_hidden, output_weights)\n",
        "output_layer_activation = np.add(output_dot_product, (bias*output_thresh))\n",
        "predicted_output = sigmoid(output_layer_activation)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz4LO3Q_3J2a",
        "outputId": "7f7c968a-854a-4499-ee66-f99dbe4769e4"
      },
      "source": [
        "print(f\"Epochs: {epochs}\")\n",
        "print(f\"Sum of Squared Errors: {sse}\", end=\"\\n\\n\")\n",
        "\n",
        "print(\"Final Hidden Weights: \", end=\"\")\n",
        "print(*hidden_weights)\n",
        "print(\"Final Hidden Thresholds: \", end=\"\")\n",
        "print(*hidden_thresh, end=\"\\n\\n\")\n",
        "\n",
        "print(\"Final Output Weights: \", end=\"\")\n",
        "print(*output_weights)\n",
        "print(\"Final Output Threshold: \", end=\"\")\n",
        "print(*output_thresh, end=\"\\n\\n\")\n",
        "\n",
        "print(\"Inputs: \", end=\"\")\n",
        "print(*inputs)\n",
        "print(\"Predicted Outputs: \", end=\"\")\n",
        "print(*predicted_output)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs: 56351\n",
            "Sum of Squared Errors: 0.0009999832144082935\n",
            "\n",
            "Final Hidden Weights: [4.74968225 6.38706229] [4.74958299 6.38709421]\n",
            "Final Hidden Thresholds: [7.28780511 2.84191543]\n",
            "\n",
            "Final Output Weights: [-10.39183629] [9.77621564]\n",
            "Final Output Threshold: [4.56006424]\n",
            "\n",
            "Inputs: [1 1] [0 1] [1 0] [0 0]\n",
            "Predicted Outputs: [0.01551648] [0.9849466] [0.98494544] [0.01748987]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}